{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       This was perhaps the best of Johannes Steinhof...\n",
      "1       This very fascinating book is a story written ...\n",
      "2       The four tales in this collection are beautifu...\n",
      "3       The book contained more profanity than I expec...\n",
      "4       We have now entered a second time of deep conc...\n",
      "                              ...                        \n",
      "1968    I purchased the book with the intention of tea...\n",
      "1969    There are so many design books, but the Graphi...\n",
      "1970    I am thilled to see this book being available ...\n",
      "1971    As many have stated before me the book starts ...\n",
      "1972    I love this book! It is a terrific blend of ha...\n",
      "Name: Review, Length: 1973, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "print(df['Review'])\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Plan\n",
    "\n",
    "For this project, df['Review'] will be the feature and a new column df['Genre'] will be my label. Creating a dictionary of common words associated with select genres, I will go through each review and assign it a genre based on which words it included the most. I will follow the NLP pipeline by first tokenizing and preprocessing my text before performing TF-IDF tokenization. I will be training a Logistic Regression, Random Forest, GBDT, and Decision Tree model. I will be performing a grid search to find the best hyperparameters from a parameter grid I will create. In the event that my data is imbalanced, in addition to the accuracy scores, I will find the balanced_accuracy_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: wrapt in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.12.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (2024.7.24)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, perform tokenization and processing\n",
    "\n",
    "\n",
    "#simple_preporcess removes some stop words, converts all text to lowercase, \n",
    "#removes punctuation, and tokenizes the text\n",
    "df['Review']=df['Review'].apply(lambda row: gensim.utils.simple_preprocess(row))\n",
    "\n",
    "\n",
    "genre_words={\n",
    "    'romance': ['romance','affair','affection','heart','passion'],\n",
    "    'sci-fi': ['science fiction','space', 'science','alien','sci-fi'],\n",
    "    'historical': ['history', 'historical','past','time','period','war'],\n",
    "    'fantasy': ['wizard', 'fairy','magic','magical','fantasy','dragon'],\n",
    "    'children': ['children','child','baby','kid','education','educational'],\n",
    "    'thriller': ['thriller','suspense','suspensful','tense','danger','unexpected','twist','hawking'],\n",
    "    'adventure': ['journey','adventure', 'hero','voyage','expedition']\n",
    "}\n",
    "\n",
    "def genre_finder(tokens, genre_words):\n",
    "    word_count=defaultdict(int)\n",
    "    for genre, keywords in genre_words.items():\n",
    "        for k in keywords:\n",
    "            word_count[genre]+=tokens.count(k)\n",
    "            \n",
    "    return max(word_count, key=word_count.get)\n",
    "\n",
    "\n",
    "df['Genre']=df['Review'].apply(lambda rows: genre_finder(rows, genre_words))\n",
    "\n",
    "remove_rows=df.isnull().values.any()\n",
    "if(remove_rows==True):\n",
    "    df=df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "romance       1128\n",
       "historical     539\n",
       "children       137\n",
       "sci-fi          72\n",
       "adventure       39\n",
       "thriller        32\n",
       "fantasy         26\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#start modeling process\n",
    "y=df['Genre']\n",
    "X=df['Review']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "\n",
    "def tokenized(tokens):\n",
    "    return tokens\n",
    "#Implementing TF-IDF Vectorizer to Transform Text\n",
    "tfidf_vectorizer=TfidfVectorizer(analyzer='word', tokenizer=tokenized, preprocessor=None, lowercase=False )\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train=tfidf_vectorizer.transform(X_train)\n",
    "X_test=tfidf_vectorizer.transform(X_test)\n",
    "#After this, X_train changes from an array of text reviews\n",
    "#to a sparse matrix of TF-IDF features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing grid search\n",
      "0.7854251012145749\n",
      "performing grid search\n",
      "0.7186234817813765\n",
      "performing grid search\n",
      "0.840080971659919\n",
      "performing grid search\n",
      "0.9392712550607287\n"
     ]
    }
   ],
   "source": [
    "#develop models\n",
    "lr_cvalues=[10**i for i in range(-5, 5)]\n",
    "models={}\n",
    "model_scores={}\n",
    "model_acc_scores={}\n",
    "model_predictions={}\n",
    "imbalanced_acc_scores={}\n",
    "model_names={\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'GBDT': GradientBoostingClassifier()}\n",
    "\n",
    "param_grids={\n",
    "    'Logistic Regression': {'C': lr_cvalues},\n",
    "    'Random Forest':  {'max_depth': [10, 20, 30], 'n_estimators': [10,20,30,40]}    ,\n",
    "    'Decision Tree':{ 'max_depth':[4,8,12,32] ,'min_samples_leaf':[25,50,75]   }  ,\n",
    "    'GBDT': { 'max_depth':[2,4], 'n_estimators':  [100,150] }   \n",
    "            }\n",
    "\n",
    "for name, model in model_names.items():\n",
    "    print(\"performing grid search\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=3,scoring='accuracy')\n",
    "    grid_search=grid.fit(X_train, y_train)\n",
    "    models[name]=grid_search.best_estimator_\n",
    "    model_scores[name]=grid_search.best_score_\n",
    "\n",
    "    label_prediction=models[name].predict(X_test)\n",
    "    model_predictions[name]=label_prediction\n",
    "    \n",
    "    model_acc=accuracy_score(y_test, label_prediction)\n",
    "    imbalanced_acc=balanced_accuracy_score(y_test, label_prediction)\n",
    "    #accuracy_score evaluates final model performance\n",
    "    model_acc_scores[name]=model_acc\n",
    "    imbalanced_acc_scores[name]=imbalanced_acc\n",
    "    print(model_acc_scores[name])\n",
    "best_model=max(model_acc_scores, key=model_acc_scores.get)\n",
    "best_balanced_model=max(imbalanced_acc_scores, key=imbalanced_acc_scores.get)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest accuracy score is: GBDT with a score of: 0.9392712550607287\n",
      "The model with the highest balanced accuracy score is: GBDT with a score of:0.7887588712715764 \n",
      "      Review Actual_genre Predicted_genre\n",
      "1692  Review     children          sci-fi\n",
      "1744  Review    adventure       adventure\n",
      "1236  Review      romance         romance\n",
      "21    Review      romance         romance\n",
      "894   Review      romance         romance\n",
      "...      ...          ...             ...\n",
      "1569  Review      romance         romance\n",
      "256   Review   historical      historical\n",
      "1969  Review      romance         romance\n",
      "1188  Review   historical      historical\n",
      "817   Review      romance         romance\n",
      "\n",
      "[494 rows x 3 columns]\n",
      "0.43510936331464933\n",
      "0.29089202967067107\n",
      "0.38928475828171605\n",
      "0.7887588712715764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'The model with the highest accuracy score is: {best_model} with a score of: { model_acc_scores[best_model] }')\n",
    "print(f'The model with the highest balanced accuracy score is: {best_balanced_model} with a score of:{ imbalanced_acc_scores[best_balanced_model] } ')\n",
    "#Here, I wanted to take a glance at the actual vs. predicted genres of the best-performing model\n",
    "for best_model, p in model_predictions.items():\n",
    "    df_gbdt=pd.DataFrame({\n",
    "        'Review': 'Review',\n",
    "        'Actual_genre': y_test,\n",
    "        'Predicted_genre': p\n",
    "    })\n",
    "print(df_gbdt)\n",
    "\n",
    "#The balanced accuracy scores of all the models\n",
    "for m, score in imbalanced_acc_scores.items():\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
