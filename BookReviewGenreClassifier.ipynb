{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the book reviews data set. My plan is to create a new feature called 'Genre' which will also be my label. Using unsupervised learning, my goal is to predict each review's genre, making it a multiclass classification problem. My feature right now will only be the review column. This is important because based on the genre of the review and the associated sentiment, a company can gain insight into what genre recommendations a user is likelier to enjoy. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       This was perhaps the best of Johannes Steinhof...\n",
      "1       This very fascinating book is a story written ...\n",
      "2       The four tales in this collection are beautifu...\n",
      "3       The book contained more profanity than I expec...\n",
      "4       We have now entered a second time of deep conc...\n",
      "                              ...                        \n",
      "1968    I purchased the book with the intention of tea...\n",
      "1969    There are so many design books, but the Graphi...\n",
      "1970    I am thilled to see this book being available ...\n",
      "1971    As many have stated before me the book starts ...\n",
      "1972    I love this book! It is a terrific blend of ha...\n",
      "Name: Review, Length: 1973, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "print(df['Review'])\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not be evaluating the sentiment feature. Instead, df['Review'] will be my feature and a new column df['Genre'] will be my label. Creating a dictionary of common words associated with select genres, I will go through each review and assign it a genre based on which words it included the most. I will follow the NLP pipeline by first tokenizing and preprocessing my text before performing TF-IDF tokenization. I will be training a Logistic Regression, Random Forest, GBDT, and Decision Tree model. I will be performing a grid search to find the best hyperparameters from a parameter grid I will create. In the event that my data is imbalanced, in addition to the accuracy scores, I will find the balanced_accuracy_score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: wrapt in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.12.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from nltk) (2024.7.24)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, perform tokenization and processing\n",
    "\n",
    "\n",
    "#simple_preporcess removes some stop words, converts all text to lowercase, \n",
    "#removes punctuation, and tokenizes the text\n",
    "df['Review']=df['Review'].apply(lambda row: gensim.utils.simple_preprocess(row))\n",
    "\n",
    "\n",
    "genre_words={\n",
    "    'romance': ['romance','affair','affection','heart','passion'],\n",
    "    'sci-fi': ['science fiction','space', 'science','alien','sci-fi'],\n",
    "    'historical': ['history', 'historical','past','time','period','war'],\n",
    "    'fantasy': ['wizard', 'fairy','magic','magical','fantasy','dragon'],\n",
    "    'children': ['children','child','baby','kid','education','educational'],\n",
    "    'thriller': ['thriller','suspense','suspensful','tense','danger','unexpected','twist','hawking'],\n",
    "    'adventure': ['journey','adventure', 'hero','voyage','expedition']\n",
    "}\n",
    "\n",
    "def genre_finder(tokens, genre_words):\n",
    "    word_count=defaultdict(int)\n",
    "    for genre, keywords in genre_words.items():\n",
    "        for k in keywords:\n",
    "            word_count[genre]+=tokens.count(k)\n",
    "            \n",
    "    return max(word_count, key=word_count.get)\n",
    "\n",
    "\n",
    "df['Genre']=df['Review'].apply(lambda rows: genre_finder(rows, genre_words))\n",
    "\n",
    "remove_rows=df.isnull().values.any()\n",
    "if(remove_rows==True):\n",
    "    df=df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "romance       1128\n",
       "historical     539\n",
       "children       137\n",
       "sci-fi          72\n",
       "adventure       39\n",
       "thriller        32\n",
       "fantasy         26\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#start modeling process\n",
    "y=df['Genre']\n",
    "X=df['Review']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "\n",
    "def tokenized(tokens):\n",
    "    return tokens\n",
    "#Implementing TF-IDF Vectorizer to Transform Text\n",
    "tfidf_vectorizer=TfidfVectorizer(analyzer='word', tokenizer=tokenized, preprocessor=None, lowercase=False )\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train=tfidf_vectorizer.transform(X_train)\n",
    "X_test=tfidf_vectorizer.transform(X_test)\n",
    "#After this, X_train changes from an array of text reviews\n",
    "#to a sparse matrix of TF-IDF features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing grid search\n",
      "0.7854251012145749\n",
      "performing grid search\n",
      "0.7186234817813765\n",
      "performing grid search\n",
      "0.840080971659919\n",
      "performing grid search\n",
      "0.9392712550607287\n"
     ]
    }
   ],
   "source": [
    "#develop models\n",
    "lr_cvalues=[10**i for i in range(-5, 5)]\n",
    "models={}\n",
    "model_scores={}\n",
    "model_acc_scores={}\n",
    "model_predictions={}\n",
    "imbalanced_acc_scores={}\n",
    "model_names={\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'GBDT': GradientBoostingClassifier()}\n",
    "\n",
    "param_grids={\n",
    "    'Logistic Regression': {'C': lr_cvalues},\n",
    "    'Random Forest':  {'max_depth': [10, 20, 30], 'n_estimators': [10,20,30,40]}    ,\n",
    "    'Decision Tree':{ 'max_depth':[4,8,12,32] ,'min_samples_leaf':[25,50,75]   }  ,\n",
    "    'GBDT': { 'max_depth':[2,4], 'n_estimators':  [100,150] }   \n",
    "            }\n",
    "\n",
    "for name, model in model_names.items():\n",
    "    print(\"performing grid search\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=3,scoring='accuracy')\n",
    "    grid_search=grid.fit(X_train, y_train)\n",
    "    models[name]=grid_search.best_estimator_\n",
    "    model_scores[name]=grid_search.best_score_\n",
    "\n",
    "    label_prediction=models[name].predict(X_test)\n",
    "    model_predictions[name]=label_prediction\n",
    "    \n",
    "    model_acc=accuracy_score(y_test, label_prediction)\n",
    "    imbalanced_acc=balanced_accuracy_score(y_test, label_prediction)\n",
    "    #accuracy_score evaluates final model performance\n",
    "    model_acc_scores[name]=model_acc\n",
    "    imbalanced_acc_scores[name]=imbalanced_acc\n",
    "    print(model_acc_scores[name])\n",
    "best_model=max(model_acc_scores, key=model_acc_scores.get)\n",
    "best_balanced_model=max(imbalanced_acc_scores, key=imbalanced_acc_scores.get)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest accuracy score is: GBDT with a score of: 0.9392712550607287\n",
      "The model with the highest balanced accuracy score is: GBDT with a score of:0.7887588712715764 \n",
      "      Review Actual_genre Predicted_genre\n",
      "1692  Review     children          sci-fi\n",
      "1744  Review    adventure       adventure\n",
      "1236  Review      romance         romance\n",
      "21    Review      romance         romance\n",
      "894   Review      romance         romance\n",
      "...      ...          ...             ...\n",
      "1569  Review      romance         romance\n",
      "256   Review   historical      historical\n",
      "1969  Review      romance         romance\n",
      "1188  Review   historical      historical\n",
      "817   Review      romance         romance\n",
      "\n",
      "[494 rows x 3 columns]\n",
      "0.43510936331464933\n",
      "0.29089202967067107\n",
      "0.38928475828171605\n",
      "0.7887588712715764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'The model with the highest accuracy score is: {best_model} with a score of: { model_acc_scores[best_model] }')\n",
    "print(f'The model with the highest balanced accuracy score is: {best_balanced_model} with a score of:{ imbalanced_acc_scores[best_balanced_model] } ')\n",
    "#Here, I wanted to take a glance at the actual vs. predicted genres of the best-performing model\n",
    "for best_model, p in model_predictions.items():\n",
    "    df_gbdt=pd.DataFrame({\n",
    "        'Review': 'Review',\n",
    "        'Actual_genre': y_test,\n",
    "        'Predicted_genre': p\n",
    "    })\n",
    "print(df_gbdt)\n",
    "\n",
    "#The balanced accuracy scores of all the models\n",
    "for m, score in imbalanced_acc_scores.items():\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
